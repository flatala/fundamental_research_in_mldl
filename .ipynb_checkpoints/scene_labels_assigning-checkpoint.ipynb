{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c638dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-13 21:13:30--  http://places2.csail.mit.edu/models_places365/resnet50_places365.pth.tar\n",
      "Resolving places2.csail.mit.edu (places2.csail.mit.edu)... 128.52.132.120\n",
      "Connecting to places2.csail.mit.edu (places2.csail.mit.edu)|128.52.132.120|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 97270159 (93M) [application/x-tar]\n",
      "Saving to: ‘resnet50_places365.pth.tar’\n",
      "\n",
      "resnet50_places365. 100%[===================>]  92.76M  19.7MB/s    in 4.7s    \n",
      "\n",
      "2025-05-13 21:13:35 (19.7 MB/s) - ‘resnet50_places365.pth.tar’ saved [97270159/97270159]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget http://places2.csail.mit.edu/models_places365/resnet50_places365.pth.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5409a639-b973-4ef5-bab7-7ec23585ec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-13 21:15:28--  https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6833 (6.7K) [text/plain]\n",
      "Saving to: ‘categories_places365.txt’\n",
      "\n",
      "categories_places36 100%[===================>]   6.67K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-05-13 21:15:28 (6.35 MB/s) - ‘categories_places365.txt’ saved [6833/6833]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238d1324-f3a3-4fd4-be3e-b60919de9ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup with GPU and tqdm\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "import csv\n",
    "from tqdm import tqdm  # <-- NEW\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Root directory to store model + label files\n",
    "ROOT_DIR = 'scene_classification'\n",
    "os.makedirs(ROOT_DIR, exist_ok=True)\n",
    "\n",
    "# URLs and paths\n",
    "model_url = \"http://places2.csail.mit.edu/models_places365/resnet50_places365.pth.tar\"\n",
    "label_url = \"https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt\"\n",
    "\n",
    "model_path = os.path.join(ROOT_DIR, \"resnet50_places365.pth.tar\")\n",
    "label_path = os.path.join(ROOT_DIR, \"categories_places365.txt\")\n",
    "\n",
    "# Download if missing\n",
    "if not os.path.exists(model_path):\n",
    "    subprocess.run([\"wget\", \"-O\", model_path, model_url])\n",
    "\n",
    "if not os.path.exists(label_path):\n",
    "    subprocess.run([\"wget\", \"-O\", label_path, label_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54eb198b-37b1-40c5-b71b-628ac433d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Model loading and classification functions (with GPU support)\n",
    "def load_places365_resnet50(model_path):\n",
    "    model = models.resnet50(num_classes=365)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    state_dict = {k.replace('module.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_categories(label_path):\n",
    "    with open(label_path) as f:\n",
    "        categories = [line.strip().split(' ')[0][3:] for line in f]\n",
    "    return categories\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def classify_scene_from_frame_folder(frame_folder, model, categories, num_frames=16):\n",
    "    frame_paths = glob.glob(os.path.join(frame_folder, \"*.jpg\"))\n",
    "    frame_paths = natsorted(frame_paths)\n",
    "    \n",
    "    total = len(frame_paths)\n",
    "    if total == 0:\n",
    "        return None\n",
    "\n",
    "    indices = np.linspace(0, total - 1, min(num_frames, total), dtype=int)\n",
    "    selected_paths = [frame_paths[i] for i in indices]\n",
    "\n",
    "    probs = []\n",
    "    for path in selected_paths:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            prob = torch.nn.functional.softmax(output[0], dim=0)\n",
    "            probs.append(prob.cpu())  # Move to CPU for stacking\n",
    "\n",
    "    avg_prob = torch.stack(probs).mean(dim=0)\n",
    "    top_idx = avg_prob.argmax().item()\n",
    "    return categories[top_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236022d-30a1-4d52-942c-ff6f78454a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes:   0%|          | 0/102 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Cell 3: Loop through all videos and classify scenes with tqdm\n",
    "ucf_root = \"datasets/UCF-101-JPG\"  # <-- adjust if needed\n",
    "output_csv = os.path.join(ROOT_DIR, \"scene_classification_results.csv\")\n",
    "\n",
    "model = load_places365_resnet50(model_path)\n",
    "categories = load_categories(label_path)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Traverse UCF-101-JPG/{class_name}/{video_folder}/\n",
    "class_dirs = sorted([d for d in os.listdir(ucf_root) if os.path.isdir(os.path.join(ucf_root, d))])\n",
    "\n",
    "for class_dir in tqdm(class_dirs, desc=\"Classes\"):\n",
    "    class_path = os.path.join(ucf_root, class_dir)\n",
    "    video_dirs = sorted([v for v in os.listdir(class_path) if os.path.isdir(os.path.join(class_path, v))])\n",
    "    \n",
    "    for video_dir in video_dirs:\n",
    "        video_path = os.path.join(class_path, video_dir)\n",
    "        relative_video_id = f\"{class_dir}/{video_dir}\"\n",
    "        try:\n",
    "            scene_label = classify_scene_from_frame_folder(video_path, model, categories)\n",
    "            if scene_label is not None:\n",
    "                results.append((relative_video_id, scene_label))\n",
    "            else:\n",
    "                print(f\"Skipped (no frames): {relative_video_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {relative_video_id}: {e}\")\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_csv, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['video_id', 'scene_label'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"\\n✅ Scene classification complete. CSV saved to: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
